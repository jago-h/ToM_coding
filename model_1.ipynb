{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95297713-0760-423f-867f-60eda6fcc96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elipartodikromo/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/elipartodikromo/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /Users/elipartodikromo/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <85021449-F141-385B-8151-410662B4D328> /Users/elipartodikromo/Anaconda/anaconda3/envs/mlai/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5ff6fa5-69bb-46de-acf7-d6bfa5029773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dadcc90a1cb44b49804b9453de9d24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448cd4b103cf478b9e085d9abd6bd7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d5681fd33048e09e70b75716049749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4273f7f3050247e0a4601951f992034a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0357e446-0b1b-4809-bf95-333bf20c10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"A child and a man, presumably the father, are cycling in the countryside. They are travelling up hills and eventually come to a halt. They leaves their bikes propped up against a tree. They are now on a hill overlooking the sea. The father retrieves a boat and it soon becomes apparent that the girl wont be allowed to join him on it. He sails off into the sunset as the child looks  on. Eventually he vanishes and the girl is left staring at the empty ocean. She cycles off and returns twice but although his bike is still there, the man is not. The child wears a worried expression and the film ends with a shot of the sun shining.\",\n",
    "       \"Scene opens with a father and daughter riding bikes together on a path through a field. They continue until they reach a row of trees, overlooking a body of water.  They dismount and leave the bikes by the side of the road. The father makes his way down a hill, to the water's edge, to a small rowing boat. Before getting in he climbs back up the hill and embraces his daughter a final time. He returns to the boat and rows away from land. As he travels further away the daughter runs up and down the path/cliff that overlooks the water, restlessly, as if unsure what to do next. She cycles off eventually and returns at a later date. Her father's bike is still propped up against one of the trees. She looks out across the water but it's still, lifeless. Again, she cycles off alone. \",\n",
    "       \"A father and daughter rode their bikes along a straight path without much scenery. They arrived at a tree and parked their bikes. The father descended down a steep slope to a body of water with a boat floating by the shore. The girl stayed at the top of the hill and watched his movements. The man climbed back up the hill and picked her up, hugging in a way that appeared to be a goodbye. He put her down and went back to the boat, rowing away into the sunset. The girl watched him row, moving back and forth along the plateau, until eventually she rode away on her bike, leaving her father's bike. The sun appeared to set, as the colours of the environment changed to darker and more red. She climbed a hill on her bike, and at some point returned to the trees where her father had left, but found that he had not yet returned. She rode away again. \"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "579b3a82-65f9-485d-a332-054a556a963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7be16781-5565-43a7-9d68-44e53c1fed63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8227729797363281},\n",
       " {'label': 'NEGATIVE', 'score': 0.9940113425254822},\n",
       " {'label': 'NEGATIVE', 'score': 0.9903246164321899}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ff03f5f-3ac1-4f8c-8072-1ac9cf0879a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_classification.TextClassificationPipeline"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4b3aea1-3319-48f9-a24d-758a748dd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "class preOut(TextClassificationPipeline):\n",
    "    def postprocess(self, model_outputs):\n",
    "        return model_outputs[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "086a5531-7e54-43af-b1a2-1755ef33e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = preOut(model = model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bcbf4fb-e6d5-4b9e-82c0-b2f0e7c6ace5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8993, -0.6360])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sent)[0][0] # Nodes from final layer (before softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568f42b-ab9b-40aa-9a27-75ec0a2c591d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
